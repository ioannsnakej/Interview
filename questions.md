# Вопросы собеседований на позицию DevOps-инженера
<details>
  <summary>Linux</summary>

  ### 1. Что такое load average? Что показывает эта метрика? Почему load average состоит из трёх значений?
  <details>
    <summary>Ответ</summary>

  ***LA (load average - средняя нагрузка системы)*** - параметр, определяющий среднее количество процессов, которые:
      
  - выполняются прямо сейчас (в состоянии running),
  - либо ожидают доступа к CPU или диску (в состоянии uninterruptible sleep).
      
  Значения показываются для последних 1, 5 и 15 минут. Это позволяет:

  - Оценить динамику нагрузки. Значения помогают понять, как процессы в системе нагружают CPU с течением времени.
  - Учесть не только активные процессы, но и те, которые ждут своей очереди. Это позволяет получить более полное представление о загруженности системы.
  - Учесть процессы, которые ожидают завершения операций ввода-вывода. Эти процессы могут значительно влиять на производительность системы, даже если они не занимают CPU напрямую. 
      
  #### Как посмотреть LA:
  - uptime
  - cat /proc/loadavg
  #### Как интерпритировать:
  Главное правило:
  **Сравнивайте load average с количеством ядер процессора.**
  
  Посмотреть количество ядер можно командой:
      
    nproc
  **Пример:**
  Если у вас N ядра, то:

  - load = N — система загружена на 100%
  - load < N — запас по ресурсам есть
  - load > N — ядрам не хватает времени, процессы начинают ждать
      
  #### Высокое значение не всегда значит, что процессор "зашит".
  На нагрузку влияют и другие факторы:

  |Причина|Описание|
  |-|-|
  |CPU-bound процессы|Программы, активно использующие процессор (компиляция, шифрование, вычисления).|
  |I/O wait | Задержки из-за медленного диска или файловой системы — процессы ждут завершения операций чтения/записи.|
  |Недостаток RAM | Когда система начинает использовать swap — растёт задержка и load.|
  |Блокировка ресурсов | Процессы ждут освобождения файлов, сокетов или блокировок БД.|
  |Много фоновых задач | Cron, systemd-службы, резервные копии, индексация и т.п.|
  
  Также влияние на расчета LA оказывает:
  1. Технология Hyper-Threading, которая делит одно физическое ядро на 2 логических
  2. Технология Turbo Bust, которая позволяет разгонять тактовую частоту процессора и работать на частоте выше заявленной, т.е. выше номинальной частоты (время на обработку одной задачи уменьшается).
  #### Как диагностировать:

  - htop покажет загруженность CPU и RAM, а также количество процессов в состоянии D (ожидание I/O)
  - iotop — отследит нагрузку на диск
  - iftop — покажет текущий сетевой трафик
  </details>

  ### 2. Что такое OOM killer? Для чего нужен? Как работает?
  <details>
    <summary>Ответ</summary>
    
  ***OOM Killer*** — механизм ядра Linux, который при исчерпании доступной памяти принудительно завершает отдельные процессы на сервере для освобождения RAM. Освободившаяся память передается ядру ОС, а после перенаправляется тому процессу, которому ее было недостаточно. Сообщение об этом отображается в /var/log/syslog (Debian/Ubuntu) или /var/log/messages (Centos/RHell).

  OOM Killer сканирует запущенные процессы и назначает каждому из них *oom_score* — показатель, который представляет его «вредность» или вероятность завершения. Некоторые факторы, на основе которых рассчитывается oom_score:

  - использование памяти (процессы, потребляющие больше памяти, получают более высокие оценки);
  - время работы процесса (более длительные процессы получают более низкие оценки);
  - привилегии root (процессы, запущенные под root, получают менее низкие оценки);
  - значение nice (процессы с более низким приоритетом (высокими значениями nice) получают более высокие оценки);
  - ручная настройка через oom_score_adj (настраивает вероятность завершения процесса).

  В первую очередь будут завершены недавно запущенные пользовательские процессы, которые требуют большого объема памяти и/или имеют множество дочерних процессов; в последнюю очередь будут завершаться системные процессы пользователя root, запущенные значительное время назад.
  В связи с тем, что OOM killer «убивает» процессы с помощью SIGKILL, что не дает возможности корректного завершения процессов, сохранения данных и пр., частое срабатывание этого механизма может приводить к серьезным последствиям в работе системе.

  #### Что делать:

  - Провести анализ работы сервера, баз данных, сайтов и тд с целью последующей оптимизации, чтобы устранить причину проблемы.
  - Если сервер уже оптимизирован, но памяти не хватает, то стоит задуматься о увеличении  объема RAM.
  - Также есть возможность установить приоритет определенному процессу, чтобы запретить OOM killer его завершать. Значение приоритета хранится в файле /proc/$PID/oom_adj. Для установки приоритета необходимо узнать PID конкретного процесса, после чего воспользоваться командой:
        
        echo -17 > /proc/PID_процесса/oom_adj

  Устанавливаемый приоритет в данном случае — -17. Более безопасный вариант — использовать приоритет -15. В этом случае процесс будет одним из последних, которые OOM killer завершит, но при этом отсутствует полный запрет на завершение, который в критических ситуациях может привести к kernel panic.
  </details>
  
  ### 3. Отличие hardlink от softlink (symlinks)
  <details>
    <summary>Ответ</summary>
    **Жёсткая ссылка (hardlink)** — это запись в каталоге, которая указывает непосредственно на инод файла. Она действует как отдельный файл и ссылается на конкретное место на жёстком диске. Это зеркальная копия оригинального файла.

    #### Как создать жесткую ссылку

        ln file hardlink
    
    Изменения, внесённые в hardlink, отображаются и в file, поскольку они ссылаются на один и тот же inode. Если удалить file, то содержимое файла будет доступно через hardlink

    #### Жесткие ссылки имеют следующее преимущества:

    - Эффективная компоновка: несколько жёстких ссылок могут совместно использовать один и тот же инод и блоки данных, что означает, что при создании нескольких жёстких ссылок на один файл не тратится лишнее место на диске.
    - Доступность файла: пока существует хотя бы одна жёсткая ссылка на файл, данные файла остаются доступными. Удалив одну жёсткую ссылку, мы не удаляем сам файл.
    - Производительность: жёсткие ссылки обычно срабатывают быстрее мягких, поскольку указывают непосредственно на индексный дескриптор и не требуют разрешения пути.
    - Прозрачность: жёсткие ссылки выглядят и функционируют как обычные файлы. Нет различия между исходным файлом и указывающими на него жёсткими ссылками.
    - Консистентность: все жёсткие ссылки на файл всегда актуальны. Любые изменения, внесённые через любую жёсткую ссылку, немедленно отражаются во всех остальных.

    #### Некоторые ограничения:
    - Ограничения на каталоги: жёсткие ссылки можно создавать только для обычных файлов (не для каталогов или специальных файлов).
    - Ограничение на одну файловую систему: жесткие ссылки не могут распространяться на несколько файловых систем. Они работают только в том случае, если новая жесткая ссылка существует в той же файловой системе, что и исходная.

    **Мягкая ссылка (softlink - символическая ссылка)** — это отдельный файл, содержащий путь к другому файлу или директории. В отличие от жёстких ссылок, мягкие ссылки не ссылаются напрямую на индексный дескриптор целевого файла, а имеют собственные индексные дескрипторы и содержат путь к целевому файлу или каталогу.

    #### Как создать жесткую ссылку

        ln -s file softlink

    > При создании символических ссылок следует указывать абсолютный путь, поскольку относительные пути не будут работать.

    Изменения, внесённые через softlink, отражаются в file
    
    #### Ссылки на каталоги

    Поскольку связь мягкой ссылки является логической, а не дублированием, символические ссылки могут указывать на целые каталоги или на файлы на удалённых компьютерах. Жёсткие ссылки для этого не предназначены.

    #### Символические ссылки имеют следующие преимущества:
    - Гибкость: мягкие ссылки могут указывать как на файлы, так и на директории, а также работать между разными файловыми системами или разделами.
    - Удобство: не составляет труда создавать ярлыки и организовывать файлы с помощью мягких ссылок. Они могут указывать на пока не существующие файлы и заработают, как только цель для них будет создана.
    - Низкие издержки: размер файлов символических ссылок небольшой, так как они содержат только путь к цели.
    #### У символических ссылок есть и недостатки:
    - Хрупкость: они могут стать «висячими» ссылками, если цель будет перемещена, переименована или удалена.
    - Производительность: доступ к символическим ссылкам немного медленнее, чем к жёстким, поскольку требуется дополнительный шаг разрешения пути.
    - Небезопасность: если ими неправильно управлять, мягкие ссылки могут представлять угрозу безопасности, так как могут указывать на конфиденциальные файлы.
    - Разные индексные дескрипторы: мягкие ссылки имеют собственные айноды, из-за чего количество айнодов в системе может слишком увеличиться
  </details>

</details>

<details>
<summary>k8s</summary>

  ### 1. Что такое kubernetes?
  <details>
    <summary>Ответ</summary>
      
  ***Kubernetes*** - открытое программное обеспечение для оркестрации контейнеризированных приложений — автоматизации их развёртывания, масштабирования и координации в условиях кластера.
  
  Он решает следующие задачи:

  - деплоймент — поднимает новые экземпляры приложения;
  - самовосстановление — следит за приложением, если упало, автоматически перезапускает;
  - управление — контролирует жизненный цикл приложения;
  - масштабирование — добавляет или уменьшает количество экземпляров приложения, в зависимости от нагрузки;
  - балансировка трафика — распределяет нагрузку, по экземплярам приложений.
  </details>

</details>

<details>
<summary>Docker</summary>

  ### 1. От кого по умолчанию запускается контейнер? Почему это плохо?
  <details>
    <summary>Ответ</summary>
  По умолчанию Docker использует root (UID 0).
  Ваш контейнер – это еще один процесс, запущенный пользователем root на ядре вашего хоста.
  Это означает, что уязвимость в вашем приложении, среде выполнения Docker или ядре Linux может позволить злоумышленникам выйти из контейнера и выполнить операции с правами root на вашей машине.

  #### Меры безопасности:
  **Запуск контейнеризированных приложений от имени пользователя, не являющегося привилегированным пользователем.**
  Наилучшей практикой для контейнерных приложений является запуск от имени обычного пользователя.
  Большинству программ не нужен root-доступ, поэтому смена пользователя обеспечивает немедленный уровень защиты от взлома контейнера.
  Вы должны создать новую учетную запись пользователя как один из последних этапов в вашем Dockerfile.

  Этого можно добиться с помощью инструкции `USER`:

    FROM base-image:latest
    RUN apt install demo-package
    USER demo-user:demo-group
  
  `USER` часто указывается как предпоследняя ступень в Dockerfile.
  Это означает, что вы все еще можете выполнять операции, требующие root, на более ранних этапах сборки образа.
  Инструкция `apt install` в приведенном выше примере имеет законную потребность в `root`.
  Если бы инструкция `USER` была размещена выше, `apt` был бы запущен от имени `demo-user`, который не имел бы необходимых прав.
  Поскольку инструкции Dockerfile относятся только к сборкам образов, а не к запущенным контейнерам, безопасно оставить изменение пользователя на более поздний период в Dockerfile.

  Изменение пользователя, под которым запускается контейнер, может потребовать обновления разрешений на файлы и папки, к которым он обращается.
  Установите права на все пути, которые будут использоваться вашим приложением:

    COPY initial-config.yaml /data/config.yaml
    USER demo-user:demo-group
    RUN chown demo-user:demo-group /data
  
  или

  Можно воспользоваться сокращенным вариантом, используя флаг `–chown` вместе с `copy`:

    COPY --chown=demo-user:demo-group initial-config.yaml /data/config.yaml
  </details>
</details>